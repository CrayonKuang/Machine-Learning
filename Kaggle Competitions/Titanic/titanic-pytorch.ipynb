{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-10T14:12:37.727145Z","iopub.execute_input":"2023-12-10T14:12:37.727935Z","iopub.status.idle":"2023-12-10T14:12:37.736538Z","shell.execute_reply.started":"2023-12-10T14:12:37.727902Z","shell.execute_reply":"2023-12-10T14:12:37.735558Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/titanic/train.csv\", index_col = 0)\ntest= pd.read_csv(\"/kaggle/input/titanic/test.csv\", index_col = 0)\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:37.738524Z","iopub.execute_input":"2023-12-10T14:12:37.739110Z","iopub.status.idle":"2023-12-10T14:12:37.757588Z","shell.execute_reply.started":"2023-12-10T14:12:37.739074Z","shell.execute_reply":"2023-12-10T14:12:37.756744Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"((891, 11), (418, 10))"},"metadata":{}}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:37.758607Z","iopub.execute_input":"2023-12-10T14:12:37.758861Z","iopub.status.idle":"2023-12-10T14:12:37.772685Z","shell.execute_reply.started":"2023-12-10T14:12:37.758840Z","shell.execute_reply":"2023-12-10T14:12:37.771747Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"             Survived  Pclass  \\\nPassengerId                     \n1                   0       3   \n2                   1       1   \n3                   1       3   \n4                   1       1   \n5                   0       3   \n\n                                                          Name     Sex   Age  \\\nPassengerId                                                                    \n1                                      Braund, Mr. Owen Harris    male  22.0   \n2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n3                                       Heikkinen, Miss. Laina  female  26.0   \n4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n5                                     Allen, Mr. William Henry    male  35.0   \n\n             SibSp  Parch            Ticket     Fare Cabin Embarked  \nPassengerId                                                          \n1                1      0         A/5 21171   7.2500   NaN        S  \n2                1      0          PC 17599  71.2833   C85        C  \n3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n4                1      0            113803  53.1000  C123        S  \n5                0      0            373450   8.0500   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:37.773696Z","iopub.execute_input":"2023-12-10T14:12:37.773939Z","iopub.status.idle":"2023-12-10T14:12:37.789039Z","shell.execute_reply.started":"2023-12-10T14:12:37.773917Z","shell.execute_reply":"2023-12-10T14:12:37.788181Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"             Pclass                                          Name     Sex  \\\nPassengerId                                                                 \n892               3                              Kelly, Mr. James    male   \n893               3              Wilkes, Mrs. James (Ellen Needs)  female   \n894               2                     Myles, Mr. Thomas Francis    male   \n895               3                              Wirz, Mr. Albert    male   \n896               3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n              Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \nPassengerId                                                       \n892          34.5      0      0   330911   7.8292   NaN        Q  \n893          47.0      1      0   363272   7.0000   NaN        S  \n894          62.0      0      0   240276   9.6875   NaN        Q  \n895          27.0      0      0   315154   8.6625   NaN        S  \n896          22.0      1      1  3101298  12.2875   NaN        S  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892</th>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>893</th>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 1. Basic EDA","metadata":{}},{"cell_type":"code","source":"desc = pd.DataFrame(index = list(train))\ndesc['count'] = train.count()\ndesc['nunique'] = train.nunique()\ndesc['%unique'] = desc['nunique'] / len(train) * 100\ndesc['null'] = train.isnull().sum()\ndesc['type'] = train.dtypes\ndesc = pd.concat([desc, train.describe().T], axis = 1)\ndesc","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:37.791079Z","iopub.execute_input":"2023-12-10T14:12:37.791398Z","iopub.status.idle":"2023-12-10T14:12:37.833353Z","shell.execute_reply.started":"2023-12-10T14:12:37.791367Z","shell.execute_reply":"2023-12-10T14:12:37.832554Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"          count  nunique     %unique  null     type  count       mean  \\\nSurvived    891        2    0.224467     0    int64  891.0   0.383838   \nPclass      891        3    0.336700     0    int64  891.0   2.308642   \nName        891      891  100.000000     0   object    NaN        NaN   \nSex         891        2    0.224467     0   object    NaN        NaN   \nAge         714       88    9.876543   177  float64  714.0  29.699118   \nSibSp       891        7    0.785634     0    int64  891.0   0.523008   \nParch       891        7    0.785634     0    int64  891.0   0.381594   \nTicket      891      681   76.430976     0   object    NaN        NaN   \nFare        891      248   27.833895     0  float64  891.0  32.204208   \nCabin       204      147   16.498316   687   object    NaN        NaN   \nEmbarked    889        3    0.336700     2   object    NaN        NaN   \n\n                std   min      25%      50%   75%       max  \nSurvived   0.486592  0.00   0.0000   0.0000   1.0    1.0000  \nPclass     0.836071  1.00   2.0000   3.0000   3.0    3.0000  \nName            NaN   NaN      NaN      NaN   NaN       NaN  \nSex             NaN   NaN      NaN      NaN   NaN       NaN  \nAge       14.526497  0.42  20.1250  28.0000  38.0   80.0000  \nSibSp      1.102743  0.00   0.0000   0.0000   1.0    8.0000  \nParch      0.806057  0.00   0.0000   0.0000   0.0    6.0000  \nTicket          NaN   NaN      NaN      NaN   NaN       NaN  \nFare      49.693429  0.00   7.9104  14.4542  31.0  512.3292  \nCabin           NaN   NaN      NaN      NaN   NaN       NaN  \nEmbarked        NaN   NaN      NaN      NaN   NaN       NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>nunique</th>\n      <th>%unique</th>\n      <th>null</th>\n      <th>type</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Survived</th>\n      <td>891</td>\n      <td>2</td>\n      <td>0.224467</td>\n      <td>0</td>\n      <td>int64</td>\n      <td>891.0</td>\n      <td>0.383838</td>\n      <td>0.486592</td>\n      <td>0.00</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>1.0</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>Pclass</th>\n      <td>891</td>\n      <td>3</td>\n      <td>0.336700</td>\n      <td>0</td>\n      <td>int64</td>\n      <td>891.0</td>\n      <td>2.308642</td>\n      <td>0.836071</td>\n      <td>1.00</td>\n      <td>2.0000</td>\n      <td>3.0000</td>\n      <td>3.0</td>\n      <td>3.0000</td>\n    </tr>\n    <tr>\n      <th>Name</th>\n      <td>891</td>\n      <td>891</td>\n      <td>100.000000</td>\n      <td>0</td>\n      <td>object</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Sex</th>\n      <td>891</td>\n      <td>2</td>\n      <td>0.224467</td>\n      <td>0</td>\n      <td>object</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Age</th>\n      <td>714</td>\n      <td>88</td>\n      <td>9.876543</td>\n      <td>177</td>\n      <td>float64</td>\n      <td>714.0</td>\n      <td>29.699118</td>\n      <td>14.526497</td>\n      <td>0.42</td>\n      <td>20.1250</td>\n      <td>28.0000</td>\n      <td>38.0</td>\n      <td>80.0000</td>\n    </tr>\n    <tr>\n      <th>SibSp</th>\n      <td>891</td>\n      <td>7</td>\n      <td>0.785634</td>\n      <td>0</td>\n      <td>int64</td>\n      <td>891.0</td>\n      <td>0.523008</td>\n      <td>1.102743</td>\n      <td>0.00</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>1.0</td>\n      <td>8.0000</td>\n    </tr>\n    <tr>\n      <th>Parch</th>\n      <td>891</td>\n      <td>7</td>\n      <td>0.785634</td>\n      <td>0</td>\n      <td>int64</td>\n      <td>891.0</td>\n      <td>0.381594</td>\n      <td>0.806057</td>\n      <td>0.00</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>6.0000</td>\n    </tr>\n    <tr>\n      <th>Ticket</th>\n      <td>891</td>\n      <td>681</td>\n      <td>76.430976</td>\n      <td>0</td>\n      <td>object</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Fare</th>\n      <td>891</td>\n      <td>248</td>\n      <td>27.833895</td>\n      <td>0</td>\n      <td>float64</td>\n      <td>891.0</td>\n      <td>32.204208</td>\n      <td>49.693429</td>\n      <td>0.00</td>\n      <td>7.9104</td>\n      <td>14.4542</td>\n      <td>31.0</td>\n      <td>512.3292</td>\n    </tr>\n    <tr>\n      <th>Cabin</th>\n      <td>204</td>\n      <td>147</td>\n      <td>16.498316</td>\n      <td>687</td>\n      <td>object</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Embarked</th>\n      <td>889</td>\n      <td>3</td>\n      <td>0.336700</td>\n      <td>2</td>\n      <td>object</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Based on this table, we can notice a few details:\n* 'Age', 'Cabin' and 'Embarked' have null values. We have to decide whether to remove these columns or to replace null values with mean/median.\n* 'Pclass' is a categorical feature, but its dtype is 'int64'. We would have to change the dtype to 'category' or 'object'.","metadata":{}},{"cell_type":"code","source":"train['Pclass'] = train['Pclass'].astype('category')\ntest['Pclass'] = test['Pclass'].astype('category')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:37.834408Z","iopub.execute_input":"2023-12-10T14:12:37.834744Z","iopub.status.idle":"2023-12-10T14:12:37.841125Z","shell.execute_reply.started":"2023-12-10T14:12:37.834714Z","shell.execute_reply":"2023-12-10T14:12:37.840241Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"The 'Name', 'Ticket' and 'Cabin' do not provide any useful information, so we can remove it.","metadata":{}},{"cell_type":"code","source":"useless_columns = ['Name', 'Ticket', 'Cabin']\ntrain = train.drop(useless_columns, axis =1)\ntest = test.drop(useless_columns, axis = 1)\ntrain.shape,test.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:37.842146Z","iopub.execute_input":"2023-12-10T14:12:37.842420Z","iopub.status.idle":"2023-12-10T14:12:37.851673Z","shell.execute_reply.started":"2023-12-10T14:12:37.842396Z","shell.execute_reply":"2023-12-10T14:12:37.850796Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"((891, 8), (418, 7))"},"metadata":{}}]},{"cell_type":"code","source":"X = train.drop('Survived', axis = 1)\ny = train['Survived'].values","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:37.853346Z","iopub.execute_input":"2023-12-10T14:12:37.854075Z","iopub.status.idle":"2023-12-10T14:12:37.860150Z","shell.execute_reply.started":"2023-12-10T14:12:37.854040Z","shell.execute_reply":"2023-12-10T14:12:37.859270Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"categorical_cols = [col for col in X.columns if X[col].nunique() < 15 and X[col].dtype in [\"object\",\"category\"]]\nnumerical_cols = [col for col in X.columns if X[col].dtype in ['int64','float64']]\ntraining_cols = categorical_cols + numerical_cols\ntraining_cols","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:37.861242Z","iopub.execute_input":"2023-12-10T14:12:37.861509Z","iopub.status.idle":"2023-12-10T14:12:37.872364Z","shell.execute_reply.started":"2023-12-10T14:12:37.861467Z","shell.execute_reply":"2023-12-10T14:12:37.871426Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"['Pclass', 'Sex', 'Embarked', 'Age', 'SibSp', 'Parch', 'Fare']"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. Data preprocessing","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:37.873452Z","iopub.execute_input":"2023-12-10T14:12:37.873791Z","iopub.status.idle":"2023-12-10T14:12:38.204881Z","shell.execute_reply.started":"2023-12-10T14:12:37.873764Z","shell.execute_reply":"2023-12-10T14:12:38.204137Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"In this section, we will have to deal with the null values and also convert the categorical data using one hot encoder","metadata":{}},{"cell_type":"code","source":"numerical_transformer = SimpleImputer(strategy='mean')\ncategorical_transformer = Pipeline(steps=[\n    (\"impute\",SimpleImputer(strategy=\"most_frequent\")),\n    ('encode', OneHotEncoder(handle_unknown=\"ignore\"))\n])\npreprocessor = ColumnTransformer(transformers=[\n    ('numerical',numerical_transformer,numerical_cols),\n    ('categorical',categorical_transformer,categorical_cols)\n], remainder = 'passthrough')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:38.207500Z","iopub.execute_input":"2023-12-10T14:12:38.207798Z","iopub.status.idle":"2023-12-10T14:12:38.213048Z","shell.execute_reply.started":"2023-12-10T14:12:38.207774Z","shell.execute_reply":"2023-12-10T14:12:38.212088Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"X = preprocessor.fit_transform(X)\ntest_processed = preprocessor.fit_transform(test)\nX.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:38.214049Z","iopub.execute_input":"2023-12-10T14:12:38.214322Z","iopub.status.idle":"2023-12-10T14:12:38.258368Z","shell.execute_reply.started":"2023-12-10T14:12:38.214270Z","shell.execute_reply":"2023-12-10T14:12:38.257528Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"((891, 12), (418, 7))"},"metadata":{}}]},{"cell_type":"markdown","source":"Next, we split the data into training and validation sets in the ratio of 80:20.","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X,\n                                                 y,\n                                                 test_size = 0.2,\n                                                 random_state = 42)\nlen(X_train), len(X_val), len(y_train), len(y_val)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:38.259395Z","iopub.execute_input":"2023-12-10T14:12:38.259662Z","iopub.status.idle":"2023-12-10T14:12:38.267707Z","shell.execute_reply.started":"2023-12-10T14:12:38.259640Z","shell.execute_reply":"2023-12-10T14:12:38.266789Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(712, 179, 712, 179)"},"metadata":{}}]},{"cell_type":"code","source":"print(X_train[:5], X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:38.268835Z","iopub.execute_input":"2023-12-10T14:12:38.269125Z","iopub.status.idle":"2023-12-10T14:12:38.277935Z","shell.execute_reply.started":"2023-12-10T14:12:38.269091Z","shell.execute_reply":"2023-12-10T14:12:38.276975Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"[[45.5     0.      0.     28.5     1.      0.      0.      0.      1.\n   0.      0.      1.    ]\n [23.      0.      0.     13.      0.      1.      0.      0.      1.\n   0.      0.      1.    ]\n [32.      0.      0.      7.925   0.      0.      1.      0.      1.\n   0.      0.      1.    ]\n [26.      1.      0.      7.8542  0.      0.      1.      0.      1.\n   0.      0.      1.    ]\n [ 6.      4.      2.     31.275   0.      0.      1.      1.      0.\n   0.      0.      1.    ]] (712, 12)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We have to standardise the input variables before putting them in the neural network.","metadata":{}},{"cell_type":"code","source":"sc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_val = sc.transform(X_val)\ntest_values = sc.transform(test_processed)\nprint(X_train[:5], X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:38.279110Z","iopub.execute_input":"2023-12-10T14:12:38.279978Z","iopub.status.idle":"2023-12-10T14:12:38.289959Z","shell.execute_reply.started":"2023-12-10T14:12:38.279943Z","shell.execute_reply":"2023-12-10T14:12:38.289002Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"[[ 1.22920747 -0.47072241 -0.47934164 -0.07868358  1.8352379  -0.51880845\n  -1.1258401  -0.7243102   0.7243102  -0.46146201 -0.30335547  0.59248936]\n [-0.50350514 -0.47072241 -0.47934164 -0.37714494 -0.54488848  1.92749365\n  -1.1258401  -0.7243102   0.7243102  -0.46146201 -0.30335547  0.59248936]\n [ 0.18957991 -0.47072241 -0.47934164 -0.47486697 -0.54488848 -0.51880845\n   0.8882256  -0.7243102   0.7243102  -0.46146201 -0.30335547  0.59248936]\n [-0.27247679  0.37992316 -0.47934164 -0.47623026 -0.54488848 -0.51880845\n   0.8882256  -0.7243102   0.7243102  -0.46146201 -0.30335547  0.59248936]\n [-1.81266577  2.93185988  2.04874166 -0.02524937 -0.54488848 -0.51880845\n   0.8882256   1.38062393 -1.38062393 -0.46146201 -0.30335547  0.59248936]] (712, 12)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(y[:5])","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:38.291047Z","iopub.execute_input":"2023-12-10T14:12:38.291341Z","iopub.status.idle":"2023-12-10T14:12:38.297192Z","shell.execute_reply.started":"2023-12-10T14:12:38.291318Z","shell.execute_reply":"2023-12-10T14:12:38.296290Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"[0 1 1 1 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 3. Set up PyTorch ANN","metadata":{}},{"cell_type":"code","source":"# Device agnostic code\nimport torch\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:38.298451Z","iopub.execute_input":"2023-12-10T14:12:38.298778Z","iopub.status.idle":"2023-12-10T14:12:39.858829Z","shell.execute_reply.started":"2023-12-10T14:12:38.298753Z","shell.execute_reply":"2023-12-10T14:12:39.857803Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"# Transform the data into tensors\nX_train = torch.tensor(X_train, dtype = torch.float32)\nX_val = torch.tensor(X_val, dtype = torch.float32)\ny_train = torch.tensor(y_train, dtype = torch.float32)\ny_val = torch.tensor(y_val, dtype = torch.float32)\ntest_tensor = torch.tensor(test_values, dtype = torch.float32)\nprint(X_train[:5], X_train.dtype, X.shape)\nprint(y_train[:5], y_train.dtype, y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:39.860425Z","iopub.execute_input":"2023-12-10T14:12:39.862033Z","iopub.status.idle":"2023-12-10T14:12:39.964692Z","shell.execute_reply.started":"2023-12-10T14:12:39.861993Z","shell.execute_reply":"2023-12-10T14:12:39.963700Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"tensor([[ 1.2292, -0.4707, -0.4793, -0.0787,  1.8352, -0.5188, -1.1258, -0.7243,\n          0.7243, -0.4615, -0.3034,  0.5925],\n        [-0.5035, -0.4707, -0.4793, -0.3771, -0.5449,  1.9275, -1.1258, -0.7243,\n          0.7243, -0.4615, -0.3034,  0.5925],\n        [ 0.1896, -0.4707, -0.4793, -0.4749, -0.5449, -0.5188,  0.8882, -0.7243,\n          0.7243, -0.4615, -0.3034,  0.5925],\n        [-0.2725,  0.3799, -0.4793, -0.4762, -0.5449, -0.5188,  0.8882, -0.7243,\n          0.7243, -0.4615, -0.3034,  0.5925],\n        [-1.8127,  2.9319,  2.0487, -0.0252, -0.5449, -0.5188,  0.8882,  1.3806,\n         -1.3806, -0.4615, -0.3034,  0.5925]]) torch.float32 (891, 12)\ntensor([0., 0., 0., 0., 0.]) torch.float32 (891,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Subclass nn.Module to create our own PyTorch model","metadata":{}},{"cell_type":"code","source":"from torch import nn\nclass TitanicClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(in_features = 12, out_features = 100),\n            nn.ReLU(),\n            nn.Linear(in_features = 100, out_features = 100),\n            nn.ReLU(),\n            nn.Linear(in_features = 100, out_features = 100),\n            nn.ReLU(),\n            nn.Linear(in_features = 100, out_features = 1)\n        )\n    def forward(self,x):\n        return self.layers(x)\n\n# Instantiate a model and send it to the GPU\nmodel_0 = TitanicClassifier().to(device)\nmodel_0","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:39.965773Z","iopub.execute_input":"2023-12-10T14:12:39.966054Z","iopub.status.idle":"2023-12-10T14:12:43.113664Z","shell.execute_reply.started":"2023-12-10T14:12:39.966031Z","shell.execute_reply":"2023-12-10T14:12:43.112846Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"TitanicClassifier(\n  (layers): Sequential(\n    (0): Linear(in_features=12, out_features=100, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=100, out_features=100, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=100, out_features=100, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=100, out_features=1, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"Set up loss function and optimizer. Since we are dealing with a binary classification problem, we will be using nn.BCEWithLogitsLoss() as the loss function.","metadata":{}},{"cell_type":"code","source":"loss_fn = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.SGD(params = model_0.parameters(),\n                           lr = 0.03)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:43.114945Z","iopub.execute_input":"2023-12-10T14:12:43.115307Z","iopub.status.idle":"2023-12-10T14:12:43.120862Z","shell.execute_reply.started":"2023-12-10T14:12:43.115274Z","shell.execute_reply":"2023-12-10T14:12:43.119850Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# pip install torchmetrics","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:43.122110Z","iopub.execute_input":"2023-12-10T14:12:43.122422Z","iopub.status.idle":"2023-12-10T14:12:43.129731Z","shell.execute_reply.started":"2023-12-10T14:12:43.122393Z","shell.execute_reply":"2023-12-10T14:12:43.128874Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"Create an accuracy metric to evaluate our model_0 later on","metadata":{}},{"cell_type":"code","source":"from torchmetrics.classification import BinaryAccuracy\naccuracy = BinaryAccuracy().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:43.130853Z","iopub.execute_input":"2023-12-10T14:12:43.131159Z","iopub.status.idle":"2023-12-10T14:12:46.657899Z","shell.execute_reply.started":"2023-12-10T14:12:43.131136Z","shell.execute_reply":"2023-12-10T14:12:46.656764Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# 4. Create a training and validation loop for our PyTorch Neural Network","metadata":{}},{"cell_type":"code","source":"# Send data to the GPU\nX_train, X_val = X_train.to(device), X_val.to(device)\ny_train, y_val = y_train.to(device), y_val.to(device)\ntest_tensor = test_tensor.to(device)\n\nepochs = 1000\n\nfor epoch in range(epochs):\n    model_0.train()\n    \n    y_logits = model_0(X_train).squeeze(dim=1)\n    y_pred = torch.round(torch.sigmoid(y_logits))\n    \n    loss = loss_fn(y_logits, y_train)\n    acc = accuracy(y_pred, y_train)*100\n    \n    optimizer.zero_grad()\n    \n    loss.backward()\n    \n    optimizer.step()\n    \n    model_0.eval()\n    with torch.inference_mode():\n        test_logits = model_0(X_val).squeeze(dim=1)\n        test_pred = torch.round(torch.sigmoid(test_logits))\n        \n        test_loss = loss_fn(test_logits, y_val)\n        test_acc = accuracy(test_pred, y_val)*100\n    if epoch % 100 == 0:\n        print(f\"Epoch: {epoch} | Loss: {loss:.4f} | Acc: {acc:.2f}% | Test_loss: {test_loss:.4f} | Test_acc: {test_acc:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:46.661742Z","iopub.execute_input":"2023-12-10T14:12:46.662275Z","iopub.status.idle":"2023-12-10T14:12:53.202395Z","shell.execute_reply.started":"2023-12-10T14:12:46.662243Z","shell.execute_reply":"2023-12-10T14:12:53.201632Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Epoch: 0 | Loss: 0.6842 | Acc: 62.36% | Test_loss: 0.6879 | Test_acc: 58.66%\nEpoch: 100 | Loss: 0.6333 | Acc: 62.36% | Test_loss: 0.6452 | Test_acc: 58.66%\nEpoch: 200 | Loss: 0.5436 | Acc: 77.39% | Test_loss: 0.5493 | Test_acc: 75.42%\nEpoch: 300 | Loss: 0.4546 | Acc: 80.90% | Test_loss: 0.4543 | Test_acc: 79.89%\nEpoch: 400 | Loss: 0.4248 | Acc: 82.72% | Test_loss: 0.4280 | Test_acc: 81.01%\nEpoch: 500 | Loss: 0.4109 | Acc: 83.57% | Test_loss: 0.4180 | Test_acc: 82.12%\nEpoch: 600 | Loss: 0.4019 | Acc: 83.71% | Test_loss: 0.4130 | Test_acc: 82.68%\nEpoch: 700 | Loss: 0.3950 | Acc: 83.71% | Test_loss: 0.4111 | Test_acc: 82.12%\nEpoch: 800 | Loss: 0.3896 | Acc: 83.99% | Test_loss: 0.4116 | Test_acc: 82.68%\nEpoch: 900 | Loss: 0.3852 | Acc: 84.41% | Test_loss: 0.4133 | Test_acc: 83.24%\n","output_type":"stream"}]},{"cell_type":"code","source":"model_0.eval()\nwith torch.inference_mode():\n    pred = torch.round(torch.sigmoid(model_0(test_tensor)))\nfinal_pred = pred.squeeze(1).cpu().numpy()\nfinal_pred = final_pred.astype(int)\nfinal_pred[:5]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:53.206367Z","iopub.execute_input":"2023-12-10T14:12:53.206660Z","iopub.status.idle":"2023-12-10T14:12:53.215860Z","shell.execute_reply.started":"2023-12-10T14:12:53.206635Z","shell.execute_reply":"2023-12-10T14:12:53.214880Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 0])"},"metadata":{}}]},{"cell_type":"code","source":"output = pd.DataFrame({\"PassengerId\":test.index,\n                      \"Survived\":final_pred})\noutput.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:53.217233Z","iopub.execute_input":"2023-12-10T14:12:53.217648Z","iopub.status.idle":"2023-12-10T14:12:53.227361Z","shell.execute_reply.started":"2023-12-10T14:12:53.217622Z","shell.execute_reply":"2023-12-10T14:12:53.226547Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived\n0          892         0\n1          893         0\n2          894         0\n3          895         0\n4          896         0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"output.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:12:53.228465Z","iopub.execute_input":"2023-12-10T14:12:53.228805Z","iopub.status.idle":"2023-12-10T14:12:53.238297Z","shell.execute_reply.started":"2023-12-10T14:12:53.228773Z","shell.execute_reply":"2023-12-10T14:12:53.237547Z"},"trusted":true},"execution_count":42,"outputs":[]}]}